{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503a785f",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce5e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les librairies\n",
    "import numpy as np\n",
    "import shap\n",
    "import pandas  as pd\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06344cad",
   "metadata": {},
   "source": [
    "## Importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b358e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données importé ✅✅\n"
     ]
    }
   ],
   "source": [
    "# ====== Importer le jeu de données ======\n",
    "df= pd.read_excel(r\"D:\\Projects\\IT\\Data Science & IA\\Developpement_Tableau_de_Bord_de_la_Chaine_Approvisionnement_Power_BI\\data\\preprocessed_data_supply.xlsx\")\n",
    "print(\"Jeu de données importé ✅✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945f2e3",
   "metadata": {},
   "source": [
    "## Supression des colonnes inutiles et exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df620fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données exporté ✅✅\n"
     ]
    }
   ],
   "source": [
    "# Gestion des colonnes dates\n",
    "df['Estimated Delivery Date'] = pd.to_datetime(df['Estimated Delivery Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df['Estimated_day'] = df['Estimated Delivery Date'].dt.day\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "colonnes_a_effacer = [\"ID\",\"Delivery Date\",\"Item\",'Estimated Delivery Date',\"Delivery Delay\",\"Supplier\",\"Warehouse\"]\n",
    "df = df.drop(columns=colonnes_a_effacer)\n",
    "df['Estimated_day']\n",
    "\n",
    "# Exportation de la base de données\n",
    "df.to_excel(r\"D:\\Projects\\IT\\Data Science & IA\\Developpement_Tableau_de_Bord_de_la_Chaine_Approvisionnement_Power_BI\\data\\supply_data.xlsx\",index=False)\n",
    "print(\"Jeu de données exporté ✅✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904c92d",
   "metadata": {},
   "source": [
    "## Encodages des features catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05067a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestions des colonnes catégorielles\n",
    "cat_col = df.select_dtypes(include=['object']).columns.difference(['Delivery Status', 'Delivery Delay','Item']).tolist()\n",
    "\n",
    "encoded_dfs = []\n",
    "for col in cat_col:\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    df[col] = df[col].astype(str)\n",
    "    encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(df[[col]]),\n",
    "        columns=encoder.get_feature_names_out([col]),\n",
    "        index=df.index\n",
    "    )\n",
    "    encoded_dfs.append(encoded)\n",
    "\n",
    "# Fusionner les colonnes encodées et supprimer les originales\n",
    "df = df.drop(columns=cat_col)\n",
    "if encoded_dfs:\n",
    "    df = pd.concat([df] + encoded_dfs, axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d400a0",
   "metadata": {},
   "source": [
    "## Application de Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d10f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les features pertinentes\n",
      "               Features  MI Scores\n",
      "2   Transportation Cost   0.025475\n",
      "8           Region_West   0.021321\n",
      "10   Restock Needed_Yes   0.015480\n",
      "1                 Sales   0.010628\n"
     ]
    }
   ],
   "source": [
    "# Préparation des données\n",
    "x = df.drop(columns=['Delivery Status'])\n",
    "y = df['Delivery Status']\n",
    "\n",
    "# ====== Initialisation et application de Mutual Information ======\n",
    "mutual = mutual_info_classif(x, y, discrete_features='auto')\n",
    "mutual_df = pd.DataFrame({\n",
    "    \"Features\": x.columns,\n",
    "    \"MI Scores\": mutual\n",
    "}).sort_values(by=\"MI Scores\", ascending=False)\n",
    "\n",
    "mutual_selected = mutual_df[mutual_df['MI Scores'] > 0.01]\n",
    "\n",
    "# Affichage\n",
    "print(\"Les features pertinentes\")\n",
    "print(mutual_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0665b1b",
   "metadata": {},
   "source": [
    "## Application du RFE - Choix des features pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee03c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sélectionnées après RFE Index(['Stock Level', 'Sales', 'Transportation Cost',\n",
      "       'Delivery Urgency_On Time', 'Region_East', 'Region_North',\n",
      "       'Region_South', 'Region_West', 'Restock Needed_No',\n",
      "       'Restock Needed_Yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Division des données en entraînement et en test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=42,test_size=0.2)\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "model = rf.fit(x_train, y_train)\n",
    "\n",
    "# Entrapineent du modèle RFE\n",
    "rfe = RFE(rf, n_features_to_select=10, step=1)\n",
    "selector = rfe.fit(x_train,y_train)\n",
    "\n",
    "# Affichage des features pertinentes\n",
    "features_slected = x_train.columns[selector.support_]\n",
    "print(\"Features sélectionnées après RFE\", features_slected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffd4f6",
   "metadata": {},
   "source": [
    "## Application de SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c62386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features selon SHAP :\n",
      "[['Sales' 'Transportation Cost' 'Stock Level']\n",
      " ['Sales' 'Stock Level' 'Transportation Cost']\n",
      " ['Sales' 'Stock Level' 'Transportation Cost']\n",
      " ['Stock Level' 'Sales' 'Transportation Cost']\n",
      " ['Stock Level' 'Sales' 'Transportation Cost']\n",
      " ['Transportation Cost' 'Sales' 'Stock Level']\n",
      " ['Transportation Cost' 'Sales' 'Stock Level']\n",
      " ['Transportation Cost' 'Sales' 'Stock Level']\n",
      " ['Sales' 'Transportation Cost' 'Stock Level']\n",
      " ['Transportation Cost' 'Sales' 'Stock Level']]\n"
     ]
    }
   ],
   "source": [
    "# Analayse SHAP avec TreeExplainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "# Gestion des SHAP values\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_aggregated = np.mean([np.abs(sv) for sv in shap_values], axis=0)\n",
    "else: \n",
    "    shap_values_aggregated = np.abs(shap_values)\n",
    "\n",
    "# Conversion explicite des noms de colonnes en array\n",
    "columns_array = np.array(x_test.columns)\n",
    "shap_importance = shap_values_aggregated.mean(axis=0)\n",
    "shap_features = columns_array[np.argsort(-shap_importance)[:10]] #Top 10 features SHAP\n",
    "\n",
    "# Affichage\n",
    "print(\"\\nTop features selon SHAP :\")\n",
    "print(shap_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319b657",
   "metadata": {},
   "source": [
    "## Mise au propre du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829fee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Delivery Status      700 non-null    int64  \n",
      " 1   Stock Level          700 non-null    int64  \n",
      " 2   Sales                700 non-null    int64  \n",
      " 3   Transportation Cost  700 non-null    float64\n",
      " 4   Restock Needed       700 non-null    object \n",
      " 5   Region               700 non-null    object \n",
      " 6   Delivery Urgency     700 non-null    object \n",
      " 7   Estimated_day        700 non-null    int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 43.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importer le jeu de données\n",
    "dataset = pd.read_excel(r\"D:\\Projects\\IT\\Data Science & IA\\Developpement_Tableau_de_Bord_de_la_Chaine_Approvisionnement_Power_BI\\data\\supply_data.xlsx\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb1331",
   "metadata": {},
   "source": [
    "## Conversion des colonnes catégorielles encodées en colonnes brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38bed512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciblé encodée, désormais catégorisée ✅✅\n"
     ]
    }
   ],
   "source": [
    "dataset['Delivery Status'] = dataset['Delivery Status'].replace({\n",
    "    0 : \"On time\",\n",
    "    1 : \"Late\",\n",
    "    -1 : \"Missing\"\n",
    "})\n",
    "\n",
    "print(\"Ciblé encodée, désormais catégorisée ✅✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141fd9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création aléatoire réussie ✅✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Delivery Urgency\n",
       "On Time        490\n",
       "On Schedule    107\n",
       "Late           103\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = dataset[\"Delivery Urgency\"] == 'On Time'  # détecte les lignes à modifier\n",
    "indices = dataset[mask].sample(frac=0.3, random_state=42).index  # 30% des \"On Time\"\n",
    "\n",
    "# Générer une répartition aléatoire entre \"Late\" et \"On Schedule\"\n",
    "remplacement = np.random.choice(['Late', 'On Schedule'], size=len(indices), replace=True)\n",
    "\n",
    "# Appliquer les nouvelles valeurs\n",
    "dataset.loc[indices, \"Delivery Urgency\"] = remplacement\n",
    "\n",
    "print(\"Création aléatoire réussie ✅✅\")\n",
    "dataset[\"Delivery Urgency\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e74f5",
   "metadata": {},
   "source": [
    "## Création des données aléatoires dans la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87086dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation réussie ✅✅\n"
     ]
    }
   ],
   "source": [
    "# Détecter les lignes à modifier (exemple : 30% des valeurs)\n",
    "indices = dataset.sample(frac=0.3, random_state=42).index  \n",
    "\n",
    "# Générer de nouvelles valeurs aléatoires entre 1 et 17\n",
    "remplacement = np.random.randint(1, 18, size=len(indices))  # randint prend [low, high), donc 18 pour inclure 17\n",
    "\n",
    "# Appliquer les nouvelles valeurs\n",
    "dataset.loc[indices, \"Estimated_day\"] = remplacement\n",
    "\n",
    "# Afficher la répartition mise à jour\n",
    "print(\"Creation réussie ✅✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c287205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu de données brut importé ✅✅\n"
     ]
    }
   ],
   "source": [
    "# Exportation de la base de données\n",
    "dataset.to_excel(r\"D:\\Projects\\IT\\Data Science & IA\\Developpement_Tableau_de_Bord_de_la_Chaine_Approvisionnement_Power_BI\\data\\supply-chain.xlsx\",index=False)\n",
    "print(\"Jeu de données brut importé ✅✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
